# -*- coding: utf-8 -*-
"""withtgrd.ipynb

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/1n1JlQhr5-ZGJnncyiVoqYu01XnPCItFR

# Importing the Libraries
"""

# Commented out IPython magic to ensure Python compatibility.
import numpy as np
import pandas as pd
import seaborn as sns
from statsmodels.formula.api import ols     
from statsmodels.stats.anova import _get_covariance,anova_lm 

import matplotlib.pyplot as plt
# %matplotlib inline

from IPython.core.interactiveshell import InteractiveShell
InteractiveShell.ast_node_interactivity = "all"

import os 
cwd = os.getcwd()
print(cwd)

pd.options.display.max_columns = None
pd.options.display.width=None
pd.options.display.float_format = '{:,.6}'.format

import warnings
warnings.filterwarnings("ignore")

"""#Modelling"""

df = pd.read_csv("Changed.csv")

df

# Defining Dependent and Independent variables 
x= df.iloc[: , :-1]
y = df.iloc[: , [25]]

# Train - Test Split 
from sklearn.model_selection import train_test_split 
x_train,x_test,y_train,y_test = train_test_split(x,y, test_size=0.3)

"""# Modelling With Grid Search CV

### Logistic Regression
"""

# To get teh Baseline Accuracy of the Logistoc Regression Model 

from sklearn.linear_model import LogisticRegression

clf = LogisticRegression().fit(x_train,y_train)
y_pred = clf.predict(x_test)

# Model Evaluation metrics 
from sklearn.metrics import accuracy_score,recall_score,precision_score,f1_score
print('Accuracy Score : ' + str(accuracy_score(y_test,y_pred)))
print('Precision Score : ' + str(precision_score(y_test,y_pred)))
print('Recall Score : ' + str(recall_score(y_test,y_pred)))
print('F1 Score : ' + str(f1_score(y_test,y_pred)))

#Logistic Regression Classifier Confusion matrix
from sklearn.metrics import confusion_matrix

print('Confusion Matrix : \n' + str(confusion_matrix(y_test,y_pred)))

# Parameter tuning & Grid Search

from sklearn.model_selection import GridSearchCV

clf = LogisticRegression()
grid_values = {'penalty': ['l1', 'l2'],'C':[0.001,.009,0.01,.09,1,5,10,25]}
grid_clf_acc = GridSearchCV(clf, param_grid = grid_values,scoring = 'recall',cv=15)
grid_clf_acc.fit(x_train, y_train)

#Predict values based on new parameters
y_pred_acc = grid_clf_acc.predict(x_test)

# New Model Evaluation metrics 

print('Accuracy Score : ' + str(accuracy_score(y_test,y_pred_acc)))
print('Precision Score : ' + str(precision_score(y_test,y_pred_acc)))
print('Recall Score : ' + str(recall_score(y_test,y_pred_acc)))
print('F1 Score : ' + str(f1_score(y_test,y_pred_acc)))
#Logistic Regression (Grid Search) Confusion matrix
confusion_matrix(y_test,y_pred_acc)

"""The hyperparameters thatwere tuned are:
- Penalty: l1 or l2 which species the norm used in the penalization.
- C: Inverse of regularization strength- smaller values of C specify stronger regularization.

However we can see that the defualt parameters yielded an almost similar model as the accuracy hasn't increased by a significant level. However, the model obtained by grid search is a slightly better suited model

### Random Forest Classifier
"""

# To get teh Baseline Accuracy of the Random Forest Classifier Model 

from sklearn.ensemble import RandomForestClassifier

rfc=RandomForestClassifier(random_state=42).fit(x_train,y_train)
y_pred = rfc.predict(x_test)

# Model Evaluation metrics 
from sklearn.metrics import accuracy_score,recall_score,precision_score,f1_score
print('Accuracy Score : ' + str(accuracy_score(y_test,y_pred)))
print('Precision Score : ' + str(precision_score(y_test,y_pred)))
print('Recall Score : ' + str(recall_score(y_test,y_pred)))
print('F1 Score : ' + str(f1_score(y_test,y_pred)))

#Random Forest Classifier Confusion matrix
from sklearn.metrics import confusion_matrix
print('Confusion Matrix : \n' + str(confusion_matrix(y_test,y_pred)))

# Parameter tuning & Grid Search
from sklearn.ensemble import RandomForestClassifier
from sklearn.model_selection import GridSearchCV
import sys

rfc=RandomForestClassifier(random_state=42)
grid_values = {'n_estimators': [200, 500],
    'max_features': ['auto', 'sqrt', 'log2'],
    'max_depth' : [4,5,6,7,8],
    'criterion' :['gini', 'entropy']}
grid_rfc_acc = GridSearchCV(rfc, param_grid = grid_values,cv=10)
grid_rfc_acc.fit(x_train, y_train)

#Predict values based on new parameters
y_pred_acc = grid_rfc_acc.predict(x_test)

# New Model Evaluation metrics 
sys.stdout = open("rfc.txt", "w")

print('Accuracy Score : ' + str(accuracy_score(y_test,y_pred_acc)))
print('Precision Score : ' + str(precision_score(y_test,y_pred_acc)))
print('Recall Score : ' + str(recall_score(y_test,y_pred_acc)))
print('F1 Score : ' + str(f1_score(y_test,y_pred_acc)))

sys.stdout.close()

#Random Forest Classifier Model (Grid Search) Confusion matrix
confusion_matrix(y_test,y_pred_acc)

"""The parameters that are tuned :
- n_estimators
- max_features
- max_depth 
- criterion

### XGBoost Classifier
"""

# To get teh Baseline Accuracy of the XGBoost Classifier Model 

from xgboost import XGBClassifier

xgb=XGBClassifier().fit(x_train,y_train)
y_pred = xgb.predict(x_test)

# Model Evaluation metrics 
from sklearn.metrics import accuracy_score,recall_score,precision_score,f1_score
print('Accuracy Score : ' + str(accuracy_score(y_test,y_pred)))
print('Precision Score : ' + str(precision_score(y_test,y_pred)))
print('Recall Score : ' + str(recall_score(y_test,y_pred)))
print('F1 Score : ' + str(f1_score(y_test,y_pred)))

#XGBoost  Classifier Confusion matrix
from sklearn.metrics import confusion_matrix
print('Confusion Matrix : \n' + str(confusion_matrix(y_test,y_pred)))

# Parameter tuning & Grid Search
from xgboost import XGBClassifier
from sklearn.model_selection import GridSearchCV

import sys

xgb=XGBClassifier()
grid_values = {'gamma': [0.5, 1, 1.5, 2, 5],
        'subsample': [0.6, 0.8, 1.0],
        'colsample_bytree': [0.6, 0.8, 1.0],
        'max_depth': [3, 4, 5]}
grid_xgb_acc = GridSearchCV(xgb, param_grid = grid_values,cv=10)
grid_xgb_acc.fit(x_train, y_train)

#Predict values based on new parameters
y_pred_acc = grid_xgb_acc.predict(x_test)

# New Model Evaluation metrics 

sys.stdout = open("xgb.txt", "w")

print('Accuracy Score : ' + str(accuracy_score(y_test,y_pred_acc)))
print('Precision Score : ' + str(precision_score(y_test,y_pred_acc)))
print('Recall Score : ' + str(recall_score(y_test,y_pred_acc)))
print('F1 Score : ' + str(f1_score(y_test,y_pred_acc)))

sys.stdout.close()

#XGBoost Model (Grid Search) Confusion matrix
confusion_matrix(y_test,y_pred_acc)

"""### KNN Classifier """

# To get teh Baseline Accuracy of the KNN Classifier Model 

from sklearn.neighbors import KNeighborsClassifier

knn=KNeighborsClassifier().fit(x_train,y_train)
y_pred = knn.predict(x_test)

# Model Evaluation metrics 
from sklearn.metrics import accuracy_score,recall_score,precision_score,f1_score
print('Accuracy Score : ' + str(accuracy_score(y_test,y_pred)))
print('Precision Score : ' + str(precision_score(y_test,y_pred)))
print('Recall Score : ' + str(recall_score(y_test,y_pred)))
print('F1 Score : ' + str(f1_score(y_test,y_pred)))

#KNN Classifier Confusion matrix
from sklearn.metrics import confusion_matrix
print('Confusion Matrix : \n' + str(confusion_matrix(y_test,y_pred)))

# Parameter tuning & Grid Search
from sklearn.neighbors import KNeighborsClassifier
from sklearn.model_selection import GridSearchCV

import sys

knn=KNeighborsClassifier()
grid_values = {'n_neighbors' : [5, 25],
    'weights': ['uniform', 'distance'],
    'algorithm': ['auto', 'ball_tree', 'kd_tree', 'brute']}
grid_knn_acc = GridSearchCV(knn, param_grid = grid_values,cv=10, scoring= 'accuracy', verbose = 1, n_jobs=-1)
grid_knn_acc.fit(x_train, y_train)

#Predict values based on new parameters
y_pred_acc = grid_knn_acc.predict(x_test)

# New Model Evaluation metrics 

sys.stdout = open("knn.txt", "w")

print('Accuracy Score : ' + str(accuracy_score(y_test,y_pred_acc)))
print('Precision Score : ' + str(precision_score(y_test,y_pred_acc)))
print('Recall Score : ' + str(recall_score(y_test,y_pred_acc)))
print('F1 Score : ' + str(f1_score(y_test,y_pred_acc))) 

sys.stdout.close()

#KNN Model (Grid Search) Confusion matrix
confusion_matrix(y_test,y_pred_acc)

"""###SVM Classifier"""

# To get teh Baseline Accuracy of the SVC Model 

from sklearn.svm import SVC

sv=SVC().fit(x_train,y_train)
y_pred = sv.predict(x_test)

# Model Evaluation metrics 
from sklearn.metrics import accuracy_score,recall_score,precision_score,f1_score
print('Accuracy Score : ' + str(accuracy_score(y_test,y_pred)))
print('Precision Score : ' + str(precision_score(y_test,y_pred)))
print('Recall Score : ' + str(recall_score(y_test,y_pred)))
print('F1 Score : ' + str(f1_score(y_test,y_pred)))

#SVC Confusion matrix
from sklearn.metrics import confusion_matrix
print('Confusion Matrix : \n' + str(confusion_matrix(y_test,y_pred)))

# Parameter tuning & Grid Search
from sklearn.model_selection import GridSearchCV
from sklearn.svm import SVC

import sys

sv=SVC()
grid_values = {'C': [0.1, 1, 10, 100, 1000],  
              'gamma': [1, 0.1, 0.01, 0.001, 0.0001], 
              'kernel': ['rbf']}
grid_sv_acc = GridSearchCV(sv, param_grid = grid_values,cv=10, refit = True, verbose = 3)
grid_sv_acc.fit(x_train, y_train)

#Predict values based on new parameters
y_pred_acc = grid_sv_acc.predict(x_test)

# New Model Evaluation metrics 

sys.stdout = open("sv.txt", "w")

print('Accuracy Score : ' + str(accuracy_score(y_test,y_pred_acc)))
print('Precision Score : ' + str(precision_score(y_test,y_pred_acc)))
print('Recall Score : ' + str(recall_score(y_test,y_pred_acc)))
print('F1 Score : ' + str(f1_score(y_test,y_pred_acc))) 

sys.stdout.close()

#svc Model (Grid Search) Confusion matrix
confusion_matrix(y_test,y_pred_acc)

"""### Naive Bayes"""

# To get teh Baseline Accuracy of the Naive Bayes Model 

from sklearn.naive_bayes import GaussianNB

nab=GaussianNB().fit(x_train,y_train)
y_pred = nab.predict(x_test)

# Model Evaluation metrics 
from sklearn.metrics import accuracy_score,recall_score,precision_score,f1_score
print('Accuracy Score : ' + str(accuracy_score(y_test,y_pred)))
print('Precision Score : ' + str(precision_score(y_test,y_pred)))
print('Recall Score : ' + str(recall_score(y_test,y_pred)))
print('F1 Score : ' + str(f1_score(y_test,y_pred)))

#Naive Bayes Confusion matrix
from sklearn.metrics import confusion_matrix
print('Confusion Matrix : \n' + str(confusion_matrix(y_test,y_pred)))

# Parameter tuning & Grid Search
from sklearn.model_selection import GridSearchCV
from sklearn.naive_bayes import GaussianNB

import sys

nab=GaussianNB()
grid_values = {'vec__max_df': [0.5, 0.625, 0.75, 0.875, 1.0],  
    'tfidf__norm': ['l1', 'l2'],  
    'clf__alpha': [1, 0.1, 0.01, 0.001, 0.0001, 0.00001]}
grid_nab_acc = GridSearchCV(nab, param_grid = grid_values,cv=10)
grid_nab_acc.fit(x_train, y_train)

#Predict values based on new parameters
y_pred_acc = grid_sv_acc.predict(x_test)

# New Model Evaluation metrics 

sys.stdout = open("nab.txt", "w")

print('Accuracy Score : ' + str(accuracy_score(y_test,y_pred_acc)))
print('Precision Score : ' + str(precision_score(y_test,y_pred_acc)))
print('Recall Score : ' + str(recall_score(y_test,y_pred_acc)))
print('F1 Score : ' + str(f1_score(y_test,y_pred_acc)))

sys.stdout.close()

#Naive Bayes Model (Grid Search) Confusion matrix
confusion_matrix(y_test,y_pred_acc)