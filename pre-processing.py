# -*- coding: utf-8 -*-
"""EcomChurn.ipynb

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/1PhS6jCCBFMmoUYSXvz-FNAlGGY2xfwWU

# Importing the Libraries
"""

# Commented out IPython magic to ensure Python compatibility.
import numpy as np
import pandas as pd
import seaborn as sns
from statsmodels.formula.api import ols     
from statsmodels.stats.anova import _get_covariance,anova_lm 

import matplotlib.pyplot as plt
# %matplotlib inline

from IPython.core.interactiveshell import InteractiveShell
InteractiveShell.ast_node_interactivity = "all"

import os 
cwd = os.getcwd()
print(cwd)

pd.options.display.max_columns = None
pd.options.display.width=None
pd.options.display.float_format = '{:,.6}'.format

import warnings
warnings.filterwarnings("ignore")

"""# EDA

## The Given Data
"""

df=pd.read_csv('Ecom.csv')
# Dropping the Customer ID column 
df = df.drop(['CustomerID'], axis=1) 
df.head()

"""## Replacing names of certain entries for certain variables"""

# In the variable 'PreferredLoginDevice' -  Mobile Phone and Phone (changing mobile phone to phone )
# In the variable 'PreferredPaymentMode' - Cash on Delivery & COD , CC & Credit Card ( changing them to cod and cc respectively)
# In the variable 'PreferedOrderCat' -  Mobile  and Mobile Phone (changing mobile and mobile phone to phone ) 
df["PreferredLoginDevice"].replace({"Mobile Phone": "Phone"}, inplace=True)
df["PreferredPaymentMode"].replace({"Cash on Delivery":"COD","Credit Card":"CC"},inplace = True)
df["PreferedOrderCat"].replace({"Mobile":"Mobile Phone"},inplace = True)
df

df.columns
df.shape
df.dtypes
df.info()
df.describe().T

"""# Looking at NA Values"""

print('NA Counts =============>>>',df.isna().sum().sum())
df.isna().sum()

"""We can see that the the variables that have missing values are 'Tenure', 'WareHousetoHome', 'HourSpendOnApp', 'OrderAmountHikeFromlastYear' , 'CouponUsed' , 'OrderCount', 'DaySinceLastOrder'. All of which are fortunately contimuous variables and thus we can treat them """

# Since the data has been treated for outliers, we replace the null values by median 
from numpy import nan
df.fillna(df.median(), inplace=True)

print(df.isna().sum())

"""# Outliers """

# Taking only the continuous variables 

dff = df[['Tenure','WarehouseToHome', 'HourSpendOnApp',
       'NumberOfDeviceRegistered',  'NumberOfAddress',
       'OrderAmountHikeFromlastYear', 'CouponUsed', 'OrderCount',
       'DaySinceLastOrder', 'CashbackAmount']]

Q1 = dff.quantile(0.25)
Q3 = dff.quantile(0.75)
IQR = Q3 - Q1

dff.columns
df_items = pd.DataFrame()

df_items['Q1'] = dff.quantile(0.25)
df_items['Q2'] = dff.quantile(0.50)
df_items['Q3'] = dff.quantile(0.75)
df_items['IQR'] = dff.quantile(0.75) - dff.quantile(0.25)


df_items['OutlierCount'] = ((dff < (Q1 - 1.5 * IQR)) | (dff > (Q3 + 1.5 * IQR))).sum()

df_items

median_1 = df.loc[df['NumberOfDeviceRegistered']<4, 'NumberOfDeviceRegistered'].median()
df.loc[df.NumberOfDeviceRegistered > 4, 'NumberOfDeviceRegistered'] = np.nan
df.fillna(median_1,inplace=True)

median_1_a = df.loc[df['NumberOfDeviceRegistered']>3, 'NumberOfDeviceRegistered'].median()
df.loc[df.NumberOfDeviceRegistered < 3, 'NumberOfDeviceRegistered'] = np.nan
df.fillna(median_1_a,inplace=True)

median_2 = df.loc[df['CouponUsed']<2, 'CouponUsed'].median()
df.loc[df.CouponUsed >21 , 'CouponUsed'] = np.nan
df.fillna(median_2,inplace=True)

median_3 = df.loc[df['OrderCount']<3, 'OrderCount'].median()
df.loc[df.OrderCount > 3, 'OrderCount'] = np.nan
df.fillna(median_3,inplace=True)

median_4 = df.loc[df['CashbackAmount']<196, 'CashbackAmount'].median()
df.loc[df.CashbackAmount > 196, 'CashbackAmount'] = np.nan
df.fillna(median_4,inplace=True)

dff = df[['Tenure','WarehouseToHome', 'HourSpendOnApp',
       'NumberOfDeviceRegistered',  'NumberOfAddress',
       'OrderAmountHikeFromlastYear', 'CouponUsed', 'OrderCount',
       'DaySinceLastOrder', 'CashbackAmount']]

Q1 = dff.quantile(0.25)
Q3 = dff.quantile(0.75)
IQR = Q3 - Q1

dff.columns
df_items = pd.DataFrame()

df_items['Q1'] = dff.quantile(0.25)
df_items['Q2'] = dff.quantile(0.50)
df_items['Q3'] = dff.quantile(0.75)
df_items['IQR'] = dff.quantile(0.75) - dff.quantile(0.25)


df_items['OutlierCount'] = ((dff < (Q1 - 1.5 * IQR)) | (dff > (Q3 + 1.5 * IQR))).sum()

df_items

"""# Visualising the Given Data

#Boxplot
"""

from scipy.stats import zscore

df_selected = df[['Tenure','WarehouseToHome', 'HourSpendOnApp', 'NumberOfDeviceRegistered', 'SatisfactionScore', 'NumberOfAddress', 
          'OrderAmountHikeFromlastYear', 'CouponUsed','OrderCount','DaySinceLastOrder','CashbackAmount']]

data=df_selected.apply(zscore)
data.boxplot()

"""#Density Plot"""

items = ['Tenure','WarehouseToHome', 'HourSpendOnApp', 'NumberOfDeviceRegistered', 'SatisfactionScore', 'NumberOfAddress', 
          'OrderAmountHikeFromlastYear', 'CouponUsed','OrderCount','DaySinceLastOrder','CashbackAmount']

fig, ax = plt.subplots(nrows=1, ncols=11, figsize=(30,7))
i = 0 
for item in items:
    axx=ax[i]
    null = sns.distplot(df[[item]], ax = axx, label=item, hist=True, rug=False).set_title(item, fontsize=15)
    i=i+1

"""# Transforming Variables

## We decide on Dummy- encoding the categaoriavle variables as we have to encode 5 categorical variables. 

This approach is more flexible because it allows encoding as many category columns as you would like and choose how to label the columns using a prefix.
"""

# Encoding the variable -	Preferred login device

import pandas as pd
import numpy as np
df1 = pd.get_dummies(df['PreferredLoginDevice'],drop_first=True) #To avoid the dummy variable trap 
#So basically, if it's a phone, it'll take the value of 1 and 0 if it's a computer

df = pd.concat([df1,df], axis=1)

df.drop('PreferredLoginDevice',axis=1, inplace=True)

# Encoding the variable -	Preferred Payment Method

df2 = pd.get_dummies(df['PreferredPaymentMode'],drop_first=True) #To avoid the dummy variable trap 
#So basically, if it's not a part of any of the following, then it'l;l be by "Credit Card"

df = pd.concat([df2,df], axis=1)

df.drop('PreferredPaymentMode',axis=1, inplace=True)

# Encoding the variable -	Gender

df3 = pd.get_dummies(df['Gender'],drop_first=True) #To avoid the dummy variable trap 
#So basically, if it's male it's 1 and 0 if female

df = pd.concat([df3,df], axis=1)

df.drop('Gender',axis=1, inplace=True)

# Encoding the variable -	Preferred Payment Method

df4 = pd.get_dummies(df['PreferedOrderCat'],drop_first=True) #To avoid the dummy variable trap 
#So basically, if it belongs to none, then it belongs to Fashion

df = pd.concat([df4,df], axis=1)

df.drop('PreferedOrderCat',axis=1, inplace=True)

# Encoding the variable -	Preferred Payment Method

df5 = pd.get_dummies(df['MaritalStatus'],drop_first=True) #To avoid the dummy variable trap 
#So basically, if it belongs to none, then they belong to "Divorced"

df = pd.concat([df5,df], axis=1)

df.drop('MaritalStatus',axis=1, inplace=True)

df

"""#Modelling"""

#Reordering the column sequence 
df = df[['Married',	'Single',	'Grocery',	'Laptop & Accessory',	'Mobile Phone',	'Others',	'Male',	'COD',	'Debit Card',	'E wallet',	'UPI',	'Phone',	'Tenure', 'CityTier',	'WarehouseToHome',	'HourSpendOnApp',	'NumberOfDeviceRegistered',	'SatisfactionScore',	'NumberOfAddress',	'Complain',	'OrderAmountHikeFromlastYear',	'CouponUsed',	'OrderCount',	'DaySinceLastOrder',	'CashbackAmount', 'Churn']]

df

# Defining Dependent and Independent variables 
x= df.iloc[: , :-1]
y = df.iloc[: , [25]]

# Train - Test Split 
from sklearn.model_selection import train_test_split 
x_train,x_test,y_train,y_test = train_test_split(x,y, test_size=0.3)

"""##Logistic Regression """

# Model
from sklearn.linear_model import LogisticRegression
from sklearn import metrics
logreg = LogisticRegression()
logreg.fit(x_train, y_train)

# Predicting 
y_pred = logreg.predict(x_test)
print('Accuracy of logistic regression classifier on test set: {:.2f}'.format(logreg.score(x_test, y_test)))

# Confusion Matrix

from sklearn.metrics import confusion_matrix
confusion_matrix = confusion_matrix(y_test, y_pred)
print(confusion_matrix)

# Compute precision, recall, F-measure and support
from sklearn.metrics import classification_report
print(classification_report(y_test, y_pred))

# Test 
y_pred1 = logreg.predict(x_train) 
from sklearn.metrics import confusion_matrix
confusion_matrix = confusion_matrix(y_train, y_pred1)
print(confusion_matrix)

from sklearn.metrics import classification_report
print(classification_report(y_train, y_pred1))

# ROC Curve
from sklearn.metrics import roc_auc_score
from sklearn.metrics import roc_curve
logit_roc_auc = roc_auc_score(y_test, logreg.predict(x_test))
fpr, tpr, thresholds = roc_curve(y_test, logreg.predict_proba(x_test)[:,1])
plt.figure()
plt.plot(fpr, tpr, label='Logistic Regression (area = %0.2f)' % logit_roc_auc)
plt.plot([0, 1], [0, 1],'r--')
plt.xlim([0.0, 1.0])
plt.ylim([0.0, 1.05])
plt.xlabel('False Positive Rate')
plt.ylabel('True Positive Rate')
plt.title('Receiver operating characteristic')
plt.legend(loc="lower right")
plt.savefig('Log_ROC')
plt.show()

from sklearn.metrics import roc_auc_score
auc=roc_auc_score(y_test, logreg.predict_proba(x_test)[:,1])
auc

from sklearn.metrics import roc_auc_score
auc=roc_auc_score(y_train, logreg.predict_proba(x_train)[:,1])
auc

"""## Random Forest"""

# Model 

from sklearn.ensemble import RandomForestRegressor
# Instantiate model with 1000 decision trees
rf = RandomForestRegressor(n_estimators = 1000, random_state = 42)
# Train the model on training data
rf.fit(x_train, y_train)

# Predict 
import numpy as np
import matplotlib.pyplot as plt
import pandas as pd
y_pred = rf.predict(x_test)
print(np.concatenate((y_pred.reshape(len(y_pred),1), y_test.values.reshape(len(y_test),1)),1))

# Confusion Matrix test 
from sklearn.metrics import confusion_matrix, accuracy_score
cm = confusion_matrix(y_test, y_pred.round())
print(cm)
accuracy_score(y_test, y_pred.round())

# Confusion Matrix train 
y_pred2 = rf.predict(x_train)
from sklearn.metrics import confusion_matrix, accuracy_score
cm = confusion_matrix(y_train, y_pred2.round())
print(cm)
accuracy_score(y_train, y_pred2.round())

# Compute precision, recall, F-measure and support - Test 
from sklearn.metrics import classification_report
print(classification_report(y_train, y_pred2.round()))

# Compute precision, recall, F-measure and support - Test 
from sklearn.metrics import classification_report
print(classification_report(y_test, y_pred.round()))

from sklearn.metrics import roc_auc_score
auc=roc_auc_score(y_test, rf.predict_proba(x_test)[:,1])
auc

"""## XG Boost """

#Model 

from numpy import loadtxt
from xgboost import XGBClassifier
from sklearn.model_selection import train_test_split
from sklearn.metrics import accuracy_score
# fit model no training data
model = XGBClassifier()
model.fit(x_train, y_train)

# Predictions

y_pred = model.predict(x_test)
predictions = [round(value) for value in y_pred]

# evaluate predictions
accuracy = accuracy_score(y_test, predictions)
print("Accuracy: %.2f%%" % (accuracy * 100.0))

# Confusion Matrix test 
from sklearn.metrics import confusion_matrix, accuracy_score
cm = confusion_matrix(y_test, y_pred.round())
print(cm)
accuracy_score(y_test, y_pred.round())

# Confusion Matrix train 
y_pred2 = model.predict(x_train)
from sklearn.metrics import confusion_matrix, accuracy_score
cm = confusion_matrix(y_train, y_pred2.round())
print(cm)
accuracy_score(y_train, y_pred2.round())

# Compute precision, recall, F-measure and support - Train 
from sklearn.metrics import classification_report
print(classification_report(y_train, y_pred2.round()))

# Compute precision, recall, F-measure and support - Test 
from sklearn.metrics import classification_report
print(classification_report(y_test, y_pred.round()))

from sklearn.metrics import roc_auc_score
auc=roc_auc_score(y_test, model.predict_proba(x_test)[:,1])
auc

from sklearn.metrics import roc_auc_score
auc=roc_auc_score(y_train, model.predict_proba(x_train)[:,1])
auc

"""## KNN Classifier """

# Model 
from sklearn.neighbors import KNeighborsClassifier
classifier = KNeighborsClassifier(n_neighbors = 5, metric = 'minkowski', p = 2)
classifier.fit(x_train, y_train)

# Predicting 

y_pred = classifier.predict(x_test)
print(np.concatenate((y_pred.reshape(len(y_pred),1), y_test.values.reshape(len(y_test),1)),1))

# Making the Confusion Matrix
from sklearn.metrics import confusion_matrix, accuracy_score
cm = confusion_matrix(y_test, y_pred)
print(cm)
accuracy_score(y_test, y_pred)

# Confusion Matrix train 
y_pred2 = classifier.predict(x_train)
from sklearn.metrics import confusion_matrix, accuracy_score
cm = confusion_matrix(y_train, y_pred2.round())
print(cm)
accuracy_score(y_train, y_pred2.round())

#Compute precision, recall, F-measure and support - Train 
from sklearn.metrics import classification_report
print(classification_report(y_train, y_pred2.round()))

# Compute precision, recall, F-measure and support - Test 
from sklearn.metrics import classification_report
print(classification_report(y_test, y_pred.round()))

from sklearn.metrics import roc_auc_score
auc=roc_auc_score(y_test, classifier.predict_proba(x_test)[:,1])
auc

from sklearn.metrics import roc_auc_score
auc=roc_auc_score(y_train, classifier.predict_proba(x_train)[:,1])
auc

"""## SVM"""

# Model 
from sklearn.svm import SVC
classifier = SVC(kernel = 'linear', random_state = 0, probability=True)
classifier.fit(x_train, y_train)

#Predicting
y_pred = classifier.predict(x_test)
print(np.concatenate((y_pred.reshape(len(y_pred),1), y_test.values.reshape(len(y_test),1)),1))

#Confusion Matrix
from sklearn.metrics import confusion_matrix, accuracy_score
cm = confusion_matrix(y_test, y_pred)
print(cm)
accuracy_score(y_test, y_pred)

# Confusion Matrix train 
y_pred2 = classifier.predict(x_train)
from sklearn.metrics import confusion_matrix, accuracy_score
cm = confusion_matrix(y_train, y_pred2.round())
print(cm)
accuracy_score(y_train, y_pred2.round())

#Compute precision, recall, F-measure and support - Train 
from sklearn.metrics import classification_report
print(classification_report(y_train, y_pred2.round()))

# Compute precision, recall, F-measure and support - Test 
from sklearn.metrics import classification_report
print(classification_report(y_test, y_pred.round()))

from sklearn.metrics import roc_auc_score
auc=roc_auc_score(y_test, classifier.predict_proba(x_test)[:,1])
auc

from sklearn.metrics import roc_auc_score
auc=roc_auc_score(y_train, classifier.predict_proba(x_train)[:,1])
auc

"""## Naive Bayes"""

#Model
from sklearn.naive_bayes import GaussianNB
classifier = GaussianNB()
classifier.fit(x_train, y_train)

#Prediction
y_pred = classifier.predict(x_test)
print(np.concatenate((y_pred.reshape(len(y_pred),1), y_test.values.reshape(len(y_test),1)),1))

# Making the Confusion Matrix
from sklearn.metrics import confusion_matrix, accuracy_score
cm = confusion_matrix(y_test, y_pred)
print(cm)
accuracy_score(y_test, y_pred)

# Confusion Matrix train 
y_pred2 = classifier.predict(x_train)
from sklearn.metrics import confusion_matrix, accuracy_score
cm = confusion_matrix(y_train, y_pred2.round())
print(cm)
accuracy_score(y_train, y_pred2.round())

#Compute precision, recall, F-measure and support - Train 
from sklearn.metrics import classification_report
print(classification_report(y_train, y_pred2.round()))

# Compute precision, recall, F-measure and support - Test 
from sklearn.metrics import classification_report
print(classification_report(y_test, y_pred.round()))

from sklearn.metrics import roc_auc_score
auc=roc_auc_score(y_test, classifier.predict_proba(x_test)[:,1])
auc

from sklearn.metrics import roc_auc_score
auc=roc_auc_score(y_train, classifier.predict_proba(x_train)[:,1])
auc